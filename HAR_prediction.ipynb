{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The goal of this assignment is to use the data from devices to predict users manner. Based on the belt, forearm, arm, and dumbbell of 6 participants, we use the Support Vector Machine (SVM) classification model to predict testing data and generate the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background  \n",
    "Human Activity Recognition (HAR) has been recognized as a key research area and is gaining attention by the computing research community, especially for the development of context-aware systems. \n",
    "There are many potential applications for HAR, like: elderly monitoring, life log systems for monitoring energy expenditure and for supporting weight-loss programs, and digital assistants for weight lifting exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we input the module for our later data anlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration  \n",
    "We first use pandas do read .csv file and filter out the redundant cloumns in the file. There are 52 features left after filteration, which related to 'belt', 'forearm', 'arm', and 'dumbbell'. In order to finding the best model paramaters for SVM, we use GridSearchCV to go through different parameters combination. For the validation purpose, we seperate the training data to 80/20, which 80% of the data for model building 20% of data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (11,14,19,22,25,70,73,86,87,89,90,94,97,100) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#%% Load Training Data\n",
    "df = pd.read_csv('pml-training.csv', sep=',', error_bad_lines=False) \n",
    "df_clean = df.dropna(axis=1, thresh = None)\n",
    "\n",
    "# Data Extraction\n",
    "idx = ['belt','arm','dumbbell']\n",
    "df_clean_key = []\n",
    "for i in idx:\n",
    "    df_clean_key.append(df_clean.filter(like = i, axis=1))\n",
    "\n",
    "df_data = pd.concat(df_clean_key,ignore_index=True,axis=1)\n",
    "\n",
    "df_label=df_clean.loc[:,'classe']\n",
    "\n",
    "# Transform the data valus and type to list\n",
    "data_train = df_data.values\n",
    "lbl_train_list = df_label.tolist()\n",
    "# mapping = {'A':0,'B':1,'C',2,'D':3,'E':4}    \n",
    "lbl_train = list(map(lambda x: ord(x)-ord('A'), lbl_train_list))\n",
    "lbl_train = np.array(lbl_train) # numpy.array for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Load Testing  Data\n",
    "df = pd.read_csv('pml-testing.csv', sep=',', error_bad_lines=False) \n",
    "df_clean = df.dropna(axis=1, thresh = None)\n",
    "\n",
    "idx = ['belt','arm','dumbbell']\n",
    "df_clean_key = []\n",
    "for i in idx:\n",
    "    df_clean_key.append(df_clean.filter(like = i, axis=1))\n",
    "\n",
    "df_data = pd.concat(df_clean_key,ignore_index=True,axis=1)\n",
    "\n",
    "data_test = df_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "# data_train = normalize(data_train,norm = 'l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Modeling\n",
    "We use GridSearchCV to find the best model parameters with cross validation = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3, 'kernel': 'rbf', 'tol': 1e-05}\n",
      "0.42416675160534095\n"
     ]
    }
   ],
   "source": [
    "# Find the best SVM model\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':['rbf'], 'C':[i for i in range(3,9)], 'tol':[1e-5,1e-6]}\n",
    "svc = svm.SVC(gamma=\"scale\")\n",
    "clf_sr = GridSearchCV(svc, parameters, cv=3) # cv: cross validation\n",
    "clf_sr.fit(data_train, lbl_train)\n",
    "print(clf_sr.best_params_)\n",
    "print(clf_sr.best_score_)\n",
    "# sorted(clf_sr.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then shuffle our training data and split if to 80/20 for validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1884  3808  4230 ... 11031  5179  8293]\n"
     ]
    }
   ],
   "source": [
    "#%% shuffle data for cross validation\n",
    "indices = np.arange(data_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "data_train = data_train[indices]\n",
    "lbl_train = lbl_train[indices]\n",
    "\n",
    "train_set = data_train[:19622//100*80,:]\n",
    "test_set = data_train[-19622*20//100:-1,:]\n",
    "train_set_lbl = lbl_train[:19622//100*80]\n",
    "test_set_lbl = lbl_train[-19622*20//100:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first try the Linear SVM to see the prediction result if not the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy =  73.41198979591836\n",
      "test accuracy =  72.6809378185525\n"
     ]
    }
   ],
   "source": [
    "#%% Linear SVM\n",
    "clf = LinearSVC(penalty = 'l2',dual = False, tol = 1e-6, max_iter = 10000)\n",
    "clf.fit(train_set, train_set_lbl) \n",
    "train_set_pred = clf.predict(train_set)\n",
    "test_set_pred = clf.predict(test_set)\n",
    "accuracy_train_set = sum(np.array(train_set_lbl==train_set_pred))/len(train_set_lbl)*100\n",
    "accuracy_test_set = sum(np.array(test_set_lbl==test_set_pred))/len(test_set_lbl)*100\n",
    "print('train accuracy = ',accuracy_train_set)\n",
    "print('test accuracy = ', accuracy_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then try different C, which control the soft margins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy =  99.9936224489796\n",
      "test accuracy =  93.78185524974516\n"
     ]
    }
   ],
   "source": [
    "#%% SVM with kernel: rbf, C = 5\n",
    "clf5 = SVC(gamma='scale', decision_function_shape='ovo',kernel = 'rbf',tol = 1e-5,C=5)\n",
    "clf5.fit(train_set, train_set_lbl) \n",
    "train_set_pred = clf5.predict(train_set)\n",
    "test_set_pred = clf5.predict(test_set)\n",
    "accuracy_train_set = sum(np.array(train_set_lbl==train_set_pred))/len(train_set_lbl)*100\n",
    "accuracy_test_set = sum(np.array(test_set_lbl==test_set_pred))/len(test_set_lbl)*100\n",
    "print('train accuracy = ',accuracy_train_set)\n",
    "print('test accuracy = ', accuracy_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy =  99.96811224489795\n",
      "test accuracy =  93.75637104994902\n"
     ]
    }
   ],
   "source": [
    "#%% SVM with kernel: rbf, C = 3\n",
    "clf3 = SVC(gamma='scale', decision_function_shape='ovo',kernel = 'rbf',tol = 1e-5,C=3)\n",
    "clf3.fit(train_set, train_set_lbl) \n",
    "train_set_pred = clf3.predict(train_set)\n",
    "test_set_pred = clf3.predict(test_set)\n",
    "accuracy_train_set = sum(np.array(train_set_lbl==train_set_pred))/len(train_set_lbl)*100\n",
    "accuracy_test_set = sum(np.array(test_set_lbl==test_set_pred))/len(test_set_lbl)*100\n",
    "print('train accuracy = ',accuracy_train_set)\n",
    "print('test accuracy = ', accuracy_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two results, we can see that the result is pretty much similar with slightly different.\n",
    "For the further analysis, we can try take some features off and compare the result again. This can help us distinquish if there are some redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try another model to see the faster prediction result, but with lower acacuracy. We may try different loss function to see the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy =  62.079081632653065\n",
      "test accuracy =  62.181447502548416\n"
     ]
    }
   ],
   "source": [
    "#%% SGD classifier (use as comparison)\n",
    "clf = linear_model.SGDClassifier(max_iter=10000, tol=1e-6,loss = 'perceptron')\n",
    "clf.fit(train_set, train_set_lbl)\n",
    "train_set_pred = clf.predict(train_set)\n",
    "test_set_pred = clf.predict(test_set)\n",
    "accuracy_train_set = sum(np.array(train_set_lbl==train_set_pred))/len(train_set_lbl)*100\n",
    "accuracy_test_set = sum(np.array(test_set_lbl==test_set_pred))/len(test_set_lbl)*100\n",
    "print('train accuracy = ',accuracy_train_set)\n",
    "print('test accuracy = ', accuracy_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Application\n",
    "#### Use the best model above (SVM with radio basis function(rbf) kernel and C = 3) to have our test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 4 3 1 0 0 1 2 1 0 4 4 0 1 1 1]\n",
      "[1 0 1 0 0 4 3 1 0 0 1 2 1 0 4 4 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "test_pred_C3 = clf3.predict(data_test)\n",
    "print(test_pred_C3)\n",
    "test_pred_C5 = clf5.predict(data_test)\n",
    "print(test_pred_C5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see from above the prediction result is the same. Let turn our prediciton back to class A - E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data label prediction result: \n",
      " ['B', 'A', 'B', 'A', 'A', 'E', 'D', 'B', 'A', 'A', 'B', 'C', 'B', 'A', 'E', 'E', 'A', 'B', 'B', 'B']\n",
      "Testing Data label prediction result: \n",
      " ['B', 'A', 'B', 'A', 'A', 'E', 'D', 'B', 'A', 'A', 'B', 'C', 'B', 'A', 'E', 'E', 'A', 'B', 'B', 'B']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "chars = list(string.ascii_uppercase)\n",
    "print('Testing Data label prediction result: \\n',[chars[i] for i in test_pred_C5])\n",
    "print('Testing Data label prediction result: \\n',[chars[i] for i in test_pred_C3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above are the prediction of label on testing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
